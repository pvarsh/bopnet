{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from keras import Sequential\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import LSTM, Dense, Dropout, Flatten, Activation\n",
    "\n",
    "from pyknon.genmidi import Midi\n",
    "from pyknon.music import NoteSeq, Note\n",
    "from music21 import midi, stream, converter, note, chord, instrument\n",
    "\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIDI_DIR = 'Omnibook/Midi'\n",
    "SEQ_LENGTH = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_midi(notes, name, filepath):\n",
    "    notes = [Note(note) for note in notes]\n",
    "    midi = Midi(1, tempo=90)\n",
    "    midi.seq_notes(notes, track=0)\n",
    "    midi.write(filepath)\n",
    "    \n",
    "def play_midi(filepath):\n",
    "    mf = midi.MidiFile()\n",
    "    mf.open(filepath)\n",
    "    mf.read()\n",
    "    mf.close()\n",
    "    stream = midi.translate.midiFileToStream(mf)\n",
    "    stream.show('midi')\n",
    "\n",
    "def load_midi(filepath):\n",
    "    mf = midi.MidiFile()\n",
    "    mf.open(filepath)\n",
    "    mf.read()\n",
    "    mf.close()\n",
    "    return mf\n",
    "\n",
    "def load_midi_dir(path):\n",
    "    filenames = os.listdir(path)\n",
    "    filepaths = [os.path.join(path, fn) for fn in filenames]\n",
    "    return [load_midi(fp) for fp in filepaths]\n",
    "\n",
    "def get_pitch_range(streams):\n",
    "    all_pitches = set(pitch for stream in streams for pitch in stream.pitches)\n",
    "    return min(all_pitches), max(all_pitches)\n",
    "\n",
    "def get_notes(stream):\n",
    "    return stream.elements[0].notesAndRests\n",
    "\n",
    "def get_durations(streams):\n",
    "    return set(note.duration.quarterLength for stream in streams for note in get_notes(stream))\n",
    "\n",
    "def build_indexes(pitches):\n",
    "    ind_to_pitch = dict(enumerate(pitches, 1))\n",
    "    ind_to_pitch[0] = 'rest'\n",
    "    pitch_to_ind = {v: k for k, v in ind_to_pitch.items()}\n",
    "    return pitch_to_ind, ind_to_pitch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load midi files and convert them to streams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "midi_files = load_midi_dir(MIDI_DIR)\n",
    "streams = [midi.translate.midiFileToStream(mf) for mf in midi_files]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get pitch range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_pitch, max_pitch = get_pitch_range(streams)\n",
    "min_pitch_midi = min_pitch.midi\n",
    "max_pitch_midi = max_pitch.midi\n",
    "pitches = list(range(min_pitch_midi, max_pitch_midi + 1))\n",
    "pitch_to_index, index_to_pitch = build_indexes(pitches)\n",
    "vocab_size = len(pitch_to_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get note durations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "durations = get_durations(streams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_note(note, pitch_to_index):\n",
    "    if note.isRest:\n",
    "        return pitch_to_index['rest']\n",
    "    return pitch_to_index[note.pitch.midi]\n",
    "\n",
    "def encode_notes(notes, pitch_to_index):\n",
    "    return [encode_note(note, pitch_to_index) for note in notes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_training_sequences(streams, length, pitch_to_index):\n",
    "    training_sequences = []\n",
    "    labels = []\n",
    "    for stream in streams:\n",
    "        notes = get_notes(stream)\n",
    "        for index in range(len(notes)-length):\n",
    "            encoded_notes = encode_notes(notes[index:index+length], pitch_to_index)\n",
    "            training_sequences.append(encoded_notes)\n",
    "            labels.append(encode_note(notes[index+length], pitch_to_index))\n",
    "    return training_sequences, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data, training_labels = make_training_sequences(streams, SEQ_LENGTH, pitch_to_index)\n",
    "training_data = to_categorical(training_data, num_classes=vocab_size)\n",
    "training_labels = to_categorical(training_labels, num_classes=vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (22739, 10, 33)\n",
      "Training labels shape: (22739, 33)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training data shape:\", training_data.shape)\n",
    "print(\"Training labels shape:\", training_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W&B Run: https://app.wandb.ai/pvarsh/bop-net/runs/kyne7r92\n",
      "Call `%%wandb` in the cell containing your training loop to display live results.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "W&B Run https://app.wandb.ai/pvarsh/bop-net/runs/kyne7r92"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=training_data.shape[1:], return_sequences=True))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dense(512))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(vocab_size))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "wandb.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20465 samples, validate on 2274 samples\n",
      "Epoch 1/10\n",
      "20465/20465 [==============================] - 21s 1ms/step - loss: 2.4241 - val_loss: 2.3953\n",
      "Resuming run: https://app.wandb.ai/pvarsh/bop-net/runs/kyne7r92\n",
      "Epoch 2/10\n",
      "20465/20465 [==============================] - 20s 976us/step - loss: 2.3589 - val_loss: 2.3513\n",
      "Epoch 3/10\n",
      "20465/20465 [==============================] - 18s 889us/step - loss: 2.3091 - val_loss: 2.3168\n",
      "Epoch 4/10\n",
      "20465/20465 [==============================] - 18s 869us/step - loss: 2.2603 - val_loss: 2.2859\n",
      "Epoch 5/10\n",
      "20465/20465 [==============================] - 21s 1ms/step - loss: 2.2171 - val_loss: 2.2755\n",
      "Epoch 6/10\n",
      "20465/20465 [==============================] - 18s 860us/step - loss: 2.1776 - val_loss: 2.2715\n",
      "Epoch 7/10\n",
      "20465/20465 [==============================] - 19s 933us/step - loss: 2.1277 - val_loss: 2.2428\n",
      "Epoch 8/10\n",
      "20465/20465 [==============================] - 18s 898us/step - loss: 2.0766 - val_loss: 2.2454\n",
      "Epoch 9/10\n",
      "20465/20465 [==============================] - 18s 889us/step - loss: 2.0365 - val_loss: 2.2294\n",
      "Epoch 10/10\n",
      "20465/20465 [==============================] - 18s 894us/step - loss: 1.9922 - val_loss: 2.2070\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1337b1a58>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(training_data, training_labels, epochs=10, batch_size=64, validation_split=0.1, callbacks=[WandbCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def improvise(model, start_input, index_to_note, note_to_index, sequence_length, solo_length):\n",
    "    start_input_indices = encode_notes(start_input, note_to_index)\n",
    "    \n",
    "    solo = []\n",
    "    solo.extend(start_input_indices)\n",
    "    \n",
    "    vocab_size = len(index_to_note)\n",
    "    \n",
    "    for _ in range(solo_length):\n",
    "        network_input = solo[-sequence_length:]\n",
    "        network_input = to_categorical(network_input, num_classes=vocab_size)\n",
    "        network_input = np.reshape(network_input, (1,) + network_input.shape)\n",
    "        prediction = model.predict(network_input, verbose=False)\n",
    "        prediction_note_index = int(np.random.choice(prediction.shape[1], 1, p=prediction[0]))\n",
    "        solo.append(prediction_note_index)\n",
    "    solo = [index_to_note[ind] for ind in solo]\n",
    "    return solo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_stream(notes):\n",
    "    s = stream.Stream()\n",
    "    for n in notes:\n",
    "        if n == 'rest':\n",
    "            s.append(note.Rest(type='eighth'))\n",
    "        else:\n",
    "            s.append(note.Note(n, type='eighth'))\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <div id='midiPlayerDiv142718'></div>\n",
       "                <link rel=\"stylesheet\" href=\"//cuthbertLab.github.io/music21j/css/m21.css\"\n",
       "                    type=\"text/css\" />\n",
       "                <script>\n",
       "                require.config({\n",
       "                    paths: {'music21': '//cuthbertLab.github.io/music21j/src/music21'}\n",
       "                });\n",
       "                require(['music21'], function() {\n",
       "                               mp = new music21.miditools.MidiPlayer();\n",
       "                               mp.addPlayer('#midiPlayerDiv142718');\n",
       "                               mp.base64Load('data:audio/midi;base64,TVRoZAAAAAYAAQABBABNVHJrAAAEbwD/AwAA4ABAAJA6WoQAgDoAAJA8WoQAgDwAAJA6WoQAgDoAAJA3WoQAgDcAhACQOlqEAIA6AACQPlqEAIA+AACQQVqEAIBBAACQPFqEAIA8AIQAkDVahACANQCEAJA+WoQAgD4AAJA6WoQAgDoAAJA8WoQAgDwAAJA6WoQAgDoAAJA3WoQAgDcAAJA/WoQAgD8AAJA+WoQAgD4AAJA6WoQAgDoAAJA4WoQAgDgAhACQQ1qEAIBDAIQAkEFahACAQQAAkDxahACAPAAAkDhahACAOAAAkDZahACANgAAkDdahACANwAAkEFahACAQQAAkD9ahACAPwAAkDpahACAOgAAkDdahACANwAAkDpahACAOgCEAJA9WoQAgD0AAJA6WoQAgDoAAJA2WoQAgDYAAJA8WoQAgDwAAJA6WoQAgDoAAJA1WoQAgDUAhACQPlqEAIA+AACQPFqEAIA8AACQOlqEAIA6AACQOlqEAIA6AACQOVqEAIA5AACQOlqEAIA6AACQOlqEAIA6AACQOlqEAIA6AIgAkEFahACAQQAAkERahACARAAAkEhahACASAAAkE1ahACATQAAkE1ahACATQAAkEtahACASwAAkEtahACASwCIAJBDWoQAgEMAAJBGWoQAgEYAAJBKWoQAgEoAAJBPWoQAgE8AAJBNWoQAgE0AAJBMWoQAgEwAAJBKWoQAgEoAAJBGWoQAgEYAAJBDWoQAgEMAhACQRlqEAIBGAACQSFqEAIBIAACQRlqEAIBGAACQRVqEAIBFAACQRlqEAIBGAACQQ1qEAIBDAACQQVqEAIBBAACQP1qEAIA/AACQPlqEAIA+AACQOlqEAIA6AIQAkEFahACAQQAAkENahACAQwAAkEZahACARgAAkEpahACASgAAkEpahACASgAAkEhahACASACEAJBBWoQAgEEAAJBKWoQAgEoAAJBIWoQAgEgAAJBGWoQAgEYAAJBBWoQAgEEAAJBDWoQAgEMAAJBEWoQAgEQAAJBGWoQAgEYAAJBEWoQAgEQAAJBDWoQAgEMAAJBBWoQAgEEAAJBAWoQAgEAAAJBDWoQAgEMAAJBGWoQAgEYAAJBIWoQAgEgAAJBKWoQAgEoAAJBJWoQAgEkAAJBIWoQAgEgAAJBGWoQAgEYAAJBFWoQAgEUAAJBDWoQAgEMAAJBBWoQAgEEAAJBAWoQAgEAAAJA3WoQAgDcAAJA8WoQAgDwAAJA9WoQAgD0AAJA8WoQAgDwAAJA/WoQAgD8AAJBKWoQAgEoAAJBHWoQAgEcAAJBIWoQAgEgAAJBGWoQAgEYAAJBDWoQAgEMAAJBAWoQAgEAAAJBBWoQAgEEAAJBDWoQAgEMAAJBGWoQAgEYAAJBJWoQAgEkAAJBIWoQAgEgAhACQQ1qEAIBDAACQRlqEAIBGAACQRVqEAIBFAIQAkENahACAQwAAkEFahACAQQAAkEBahACAQACEAJBGWoQAgEYAAJBDWoQAgEMAAJBAWoQAgEAAiAD/LwA=');\n",
       "                        });\n",
       "                </script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "solo = improvise(\n",
    "    model,\n",
    "    start_input=get_notes(streams[7])[:SEQ_LENGTH*4],\n",
    "    index_to_note=index_to_pitch,\n",
    "    note_to_index=pitch_to_index,\n",
    "    sequence_length=SEQ_LENGTH,\n",
    "    solo_length=100,\n",
    ")\n",
    "solo_stream = create_stream(solo)\n",
    "solo_stream.show('midi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf = midi.translate.streamToMidiFile(solo_stream)\n",
    "mf.open('bloomdido_with_rests_13_epochs.mid', 'wb')\n",
    "mf.write()\n",
    "mf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
