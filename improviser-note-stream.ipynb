{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from keras import Sequential\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import LSTM, Dense, Dropout, Flatten, Activation\n",
    "\n",
    "from pyknon.genmidi import Midi\n",
    "from pyknon.music import NoteSeq, Note\n",
    "from music21 import midi, stream, converter, note, chord, instrument\n",
    "\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIDI_DIR = 'Omnibook/Midi'\n",
    "SEQ_LENGTH = 30\n",
    "NUM_EPOCHS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_midi(notes, name, filepath):\n",
    "    notes = [Note(note) for note in notes]\n",
    "    midi = Midi(1, tempo=90)\n",
    "    midi.seq_notes(notes, track=0)\n",
    "    midi.write(filepath)\n",
    "    \n",
    "def play_midi(filepath):\n",
    "    mf = midi.MidiFile()\n",
    "    mf.open(filepath)\n",
    "    mf.read()\n",
    "    mf.close()\n",
    "    stream = midi.translate.midiFileToStream(mf)\n",
    "    stream.show('midi')\n",
    "\n",
    "def load_midi(filepath):\n",
    "    mf = midi.MidiFile()\n",
    "    mf.open(filepath)\n",
    "    mf.read()\n",
    "    mf.close()\n",
    "    return mf\n",
    "\n",
    "def load_midi_dir(path):\n",
    "    filenames = os.listdir(path)\n",
    "    filepaths = [os.path.join(path, fn) for fn in filenames]\n",
    "    return [load_midi(fp) for fp in filepaths]\n",
    "\n",
    "def get_pitch_range(streams):\n",
    "    all_pitches = set(pitch for stream in streams for pitch in stream.pitches)\n",
    "    return min(all_pitches), max(all_pitches)\n",
    "\n",
    "def get_notes(stream):\n",
    "    return stream.elements[0].notesAndRests\n",
    "\n",
    "def get_durations(streams):\n",
    "    return set(note.duration.quarterLength for stream in streams for note in get_notes(stream))\n",
    "\n",
    "def build_indexes(pitches):\n",
    "    ind_to_pitch = dict(enumerate(pitches, 1))\n",
    "    ind_to_pitch[0] = 'rest'\n",
    "    pitch_to_ind = {v: k for k, v in ind_to_pitch.items()}\n",
    "    return pitch_to_ind, ind_to_pitch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder:\n",
    "    \n",
    "    rest_code = 'rest'\n",
    "    rest_index = 0\n",
    "    \n",
    "    def __init__(self, streams, seq_length, augment_transpose=False):\n",
    "        self.streams = streams\n",
    "        self.augment_transpose = augment_transpose\n",
    "        self._seq_length = seq_length\n",
    "        self._pitches = self._make_pitches()\n",
    "        self._note_to_index, self._index_to_note = self._build_indexes()\n",
    "        self.vocab_size = len(self._note_to_index)\n",
    "        \n",
    "    def encode_note(self, note):\n",
    "        if note.isRest:\n",
    "            return self.rest_index\n",
    "        return self._note_to_index[note.pitch.midi]\n",
    "    \n",
    "    def encode_notes(self, notes):\n",
    "        return [self.encode_note(note) for note in notes]\n",
    "    \n",
    "    def decode_note(self, index):\n",
    "        note_code = self._index_to_note[index]\n",
    "        if note_code == self.rest_code:\n",
    "            return note.Rest(type='eighth')\n",
    "        return note.Note(note_code, type='eighth')\n",
    "    \n",
    "    def make_training_sequences(self):\n",
    "        training_sequences = []\n",
    "        labels = []\n",
    "        for stream in self.streams:\n",
    "            # get notes for each stream\n",
    "            notes = get_notes(stream)\n",
    "            # encode the notes\n",
    "            note_indices_sequence = self.encode_notes(notes)\n",
    "            # add augmented sequences\n",
    "            if self.augment_transpose:\n",
    "                note_indices_sequences = [\n",
    "                    self._transpose_encoded_sequence(note_indices_sequence, interval)\n",
    "                    for interval in range(1, 12)\n",
    "                ]\n",
    "            else:\n",
    "                note_indices_sequences = [note_indices_sequence]\n",
    "            # chunk sequences into training length\n",
    "            for note_sequence in note_indices_sequences:\n",
    "                for index in range(len(note_sequence)-self._seq_length):\n",
    "                    training_sequences.append(note_sequence[index:index+self._seq_length])\n",
    "                    labels.append(note_sequence[index+self._seq_length])\n",
    "        return training_sequences, labels\n",
    "\n",
    "    def _transpose_encoded_sequence(self, sequence, interval):\n",
    "        return [\n",
    "            index + interval if index != self.rest_index else self.rest_index\n",
    "            for index in sequence\n",
    "        ]\n",
    "    \n",
    "    def _make_pitches(self):\n",
    "        all_pitches = set(pitch for stream in streams for pitch in stream.pitches)\n",
    "        min_pitch, max_pitch = min(all_pitches), max(all_pitches)\n",
    "        if self.augment_transpose:\n",
    "            return list(range(min_pitch_midi, max_pitch_midi + 12))\n",
    "        return list(range(min_pitch_midi, max_pitch_midi + 1))\n",
    "    \n",
    "    def _build_indexes(self):\n",
    "        ind_to_note = dict(enumerate(self._pitches, 1))\n",
    "        ind_to_note[self.rest_index] = self.rest_code\n",
    "        note_to_ind = {v: k for k, v in ind_to_note.items()}\n",
    "        return note_to_ind, ind_to_note"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load midi files and convert them to streams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "midi_files = load_midi_dir(MIDI_DIR)\n",
    "streams = [midi.translate.midiFileToStream(mf) for mf in midi_files]\n",
    "encoder = Encoder(streams, seq_length=SEQ_LENGTH, augment_transpose=True)\n",
    "training_data, training_labels = encoder.make_training_sequences()\n",
    "training_data = to_categorical(training_data, num_classes=encoder.vocab_size)\n",
    "training_labels = to_categorical(training_labels, num_classes=encoder.vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (239129, 30, 44)\n",
      "Training labels shape: (239129, 44)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training data shape:\", training_data.shape)\n",
    "print(\"Training labels shape:\", training_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W&B Run: https://app.wandb.ai/pvarsh/bop-net/runs/oeuuowov\n",
      "Call `%%wandb` in the cell containing your training loop to display live results.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "W&B Run https://app.wandb.ai/pvarsh/bop-net/runs/oeuuowov"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=training_data.shape[1:], return_sequences=True))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dense(512))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(encoder.vocab_size))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "wandb.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 215216 samples, validate on 23913 samples\n",
      "Epoch 1/20\n",
      "215216/215216 [==============================] - 374s 2ms/step - loss: 2.6240 - val_loss: 2.4469\n",
      "Resuming run: https://app.wandb.ai/pvarsh/bop-net/runs/oeuuowov\n",
      "Epoch 2/20\n",
      "215216/215216 [==============================] - 445s 2ms/step - loss: 2.3876 - val_loss: 2.3136\n",
      "Epoch 3/20\n",
      "215216/215216 [==============================] - 373s 2ms/step - loss: 2.2906 - val_loss: 2.2345\n",
      "Epoch 4/20\n",
      "215216/215216 [==============================] - 352s 2ms/step - loss: 2.2205 - val_loss: 2.1956\n",
      "Epoch 5/20\n",
      "215216/215216 [==============================] - 351s 2ms/step - loss: 2.1716 - val_loss: 2.1629\n",
      "Epoch 6/20\n",
      "215216/215216 [==============================] - 352s 2ms/step - loss: 2.1353 - val_loss: 2.1350\n",
      "Epoch 7/20\n",
      "215216/215216 [==============================] - 369s 2ms/step - loss: 2.1041 - val_loss: 2.1285\n",
      "Epoch 8/20\n",
      "215216/215216 [==============================] - 364s 2ms/step - loss: 2.0752 - val_loss: 2.1148\n",
      "Epoch 9/20\n",
      "215216/215216 [==============================] - 365s 2ms/step - loss: 2.0551 - val_loss: 2.0991\n",
      "Epoch 10/20\n",
      "215216/215216 [==============================] - 81111s 377ms/step - loss: 2.0333 - val_loss: 2.0890\n",
      "Epoch 11/20\n",
      "215216/215216 [==============================] - 459s 2ms/step - loss: 2.0163 - val_loss: 2.0876\n",
      "Epoch 12/20\n",
      "215216/215216 [==============================] - 436s 2ms/step - loss: 1.9994 - val_loss: 2.0792\n",
      "Epoch 13/20\n",
      "215216/215216 [==============================] - 366s 2ms/step - loss: 1.9850 - val_loss: 2.0801\n",
      "Epoch 14/20\n",
      "215216/215216 [==============================] - 375s 2ms/step - loss: 1.9706 - val_loss: 2.0690\n",
      "Epoch 15/20\n",
      "215216/215216 [==============================] - 585s 3ms/step - loss: 1.9584 - val_loss: 2.0662\n",
      "Epoch 16/20\n",
      "215216/215216 [==============================] - 572s 3ms/step - loss: 1.9464 - val_loss: 2.0583\n",
      "Epoch 17/20\n",
      "215216/215216 [==============================] - 546s 3ms/step - loss: 1.9363 - val_loss: 2.0678\n",
      "Epoch 18/20\n",
      "161536/215216 [=====================>........] - ETA: 1:58 - loss: 1.9218"
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    training_data,\n",
    "    training_labels,\n",
    "    epochs=NUM_EPOCHS,\n",
    "    batch_size=64,\n",
    "    validation_split=0.1,\n",
    "    callbacks=[WandbCallback()]\n",
    ")\n",
    "model.save(\n",
    "    'model_{timestamp}_length_{seq_length}_epochs_{num_epochs}'\n",
    "    .format(\n",
    "        timestamp=datetime.now().isoformat(),\n",
    "        seq_length=SEQ_LENGTH,\n",
    "        num_epochs=NUM_EPOCHS,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "def improvise(model, start_input, index_to_note, note_to_index, sequence_length, solo_length):\n",
    "    start_input_indices = encoder.encode_notes(start_input)\n",
    "    \n",
    "    solo = []\n",
    "    solo.extend(start_input_indices)\n",
    "    \n",
    "    vocab_size = len(index_to_note)\n",
    "    \n",
    "    for _ in range(solo_length):\n",
    "        network_input = solo[-sequence_length:]\n",
    "        network_input = to_categorical(network_input, num_classes=vocab_size)\n",
    "        network_input = np.reshape(network_input, (1,) + network_input.shape)\n",
    "        prediction = model.predict(network_input, verbose=False)\n",
    "        prediction_note_index = int(np.random.choice(prediction.shape[1], 1, p=prediction[0]))\n",
    "        solo.append(prediction_note_index)\n",
    "    solo = [encoder.decode_note[ind] for ind in solo]\n",
    "    return solo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "def improvise(model, start_input, solo_length, encoder):\n",
    "    start_input_indices = encoder.encode_notes(start_input)\n",
    "    \n",
    "    solo = []\n",
    "    solo.extend(start_input_indices)\n",
    "        \n",
    "    for _ in range(solo_length):\n",
    "        network_input = solo[-encoder._seq_length:]\n",
    "        network_input = to_categorical(network_input, num_classes=encoder.vocab_size)\n",
    "        network_input = np.reshape(network_input, (1,) + network_input.shape)\n",
    "        prediction = model.predict(network_input, verbose=False)\n",
    "        prediction_note_index = int(np.random.choice(prediction.shape[1], 1, p=prediction[0]))\n",
    "        solo.append(prediction_note_index)\n",
    "    solo = [encoder.decode_note(ind) for ind in solo]\n",
    "    return solo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_stream(notes):\n",
    "    s = stream.Stream()\n",
    "    for note in notes:\n",
    "        s.append(note)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "solo = improvise(\n",
    "    model,\n",
    "    start_input=get_notes(streams[7])[:SEQ_LENGTH*4],\n",
    "    solo_length=100,\n",
    "    encoder=encoder,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <div id='midiPlayerDiv3684786'></div>\n",
       "                <link rel=\"stylesheet\" href=\"//cuthbertLab.github.io/music21j/css/m21.css\"\n",
       "                    type=\"text/css\" />\n",
       "                <script>\n",
       "                require.config({\n",
       "                    paths: {'music21': '//cuthbertLab.github.io/music21j/src/music21'}\n",
       "                });\n",
       "                require(['music21'], function() {\n",
       "                               mp = new music21.miditools.MidiPlayer();\n",
       "                               mp.addPlayer('#midiPlayerDiv3684786');\n",
       "                               mp.base64Load('data:audio/midi;base64,TVRoZAAAAAYAAQABBABNVHJrAAAEgQD/AwAA4ABAAJA6WoQAgDoAAJA8WoQAgDwAAJA6WoQAgDoAAJA3WoQAgDcAhACQOlqEAIA6AACQPlqEAIA+AACQQVqEAIBBAACQPFqEAIA8AIQAkDVahACANQCEAJA+WoQAgD4AAJA6WoQAgDoAAJA8WoQAgDwAAJA6WoQAgDoAAJA3WoQAgDcAAJA/WoQAgD8AAJA+WoQAgD4AAJA6WoQAgDoAAJA4WoQAgDgAhACQQ1qEAIBDAIQAkEFahACAQQAAkDxahACAPAAAkDhahACAOAAAkDZahACANgAAkDdahACANwAAkEFahACAQQAAkD9ahACAPwAAkDpahACAOgAAkDdahACANwAAkDpahACAOgCEAJA9WoQAgD0AAJA6WoQAgDoAAJA2WoQAgDYAAJA8WoQAgDwAAJA6WoQAgDoAAJA3WoQAgDcAAJA6WoQAgDoAAJA8WoQAgDwAAJA/WoQAgD8AhACQQ1qEAIBDAACQP1qEAIA/AACQPFqEAIA8AACQOlqEAIA6AIQAkEJahACAQgAAkEhahACASAAAkEpahACASgAAkEtahACASwAAkE1ahACATQAAkEpahACASgAAkEtahACASwAAkEpahACASgCEAJBGWoQAgEYAAJBDWoQAgEMAAJBJWoQAgEkAAJBKWoQAgEoAAJBIWoQAgEgAAJBDWoQAgEMAAJBAWoQAgEAAAJBEWoQAgEQAAJBHWoQAgEcAAJBKWoQAgEoAAJBNWoQAgE0AAJBKWoQAgEoAAJBNWoQAgE0AAJBMWoQAgEwAhACQSlqEAIBKAACQR1qEAIBHAACQTFqEAIBMAACQT1qEAIBPAIQAkEtahACASwAAkE1ahACATQAAkE9ahACATwAAkE1ahACATQAAkFBahACAUAAAkE1ahACATQAAkE5ahACATgAAkFBahACAUAAAkFRahACAVAAAkE5ahACATgCEAJBHWoQAgEcAAJBIWoQAgEgAAJBJWoQAgEkAAJBLWoQAgEsAAJBNWoQAgE0AAJBHWoQAgEcAAJBIWoQAgEgAAJBLWoQAgEsAAJBHWoQAgEcAAJBEWoQAgEQAAJBEWoQAgEQAAJBCWoQAgEIAAJBEWoQAgEQAAJBAWoQAgEAAhACQSVqEAIBJAACQR1qEAIBHAACQSVqEAIBJAACQSlqEAIBKAACQTlqEAIBOAACQSVqEAIBJAACQTlqEAIBOAACQUFqEAIBQAACQTlqEAIBOAACQUFqEAIBQAACQTlqEAIBOAACQS1qEAIBLAACQTlqEAIBOAACQS1qEAIBLAACQSVqEAIBJAIQAkEdahACARwAAkElahACASQAAkE5ahACATgAAkFJahACAUgAAkFVahACAVQAAkE5ahACATgCEAJBLWoQAgEsAAJBIWoQAgEgAAJBEWoQAgEQAAJBCWoQAgEIAAJBDWoQAgEMAAJBEWoQAgEQAAJBDWoQAgEMAAJBAWoQAgEAAAJA9WoQAgD0AAJBAWoQAgEAAAJBDWoQAgEMAAJBAWoQAgEAAiAD/LwA=');\n",
       "                        });\n",
       "                </script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "solo_stream = create_stream(solo)\n",
    "solo_stream.show('midi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf = midi.translate.streamToMidiFile(solo_stream)\n",
    "mf.open('bloomdido_with_rests_augmentation_16_epochs.mid', 'wb')\n",
    "mf.write()\n",
    "mf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
